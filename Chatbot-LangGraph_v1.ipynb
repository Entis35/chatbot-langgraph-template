{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e125434",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "ANTHROPIC_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1126e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Initialize OpenAI Chat Model\n",
    "llm_openai = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4ce5f",
   "metadata": {},
   "source": [
    "## 1. Constructing the basic langGraph flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[List[AIMessage | HumanMessage], add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0f355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    bot_response = llm.invoke(state[\"messages\"])\n",
    "    print(state[\"messages\"]+[bot_response])\n",
    "    print(\"\\n\")\n",
    "    return {\"messages\": [bot_response]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f799c4",
   "metadata": {},
   "source": [
    "### Show the visual graph node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d4268",
   "metadata": {},
   "source": [
    "### Run the chatbot using \"graph.stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91121299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "# value[\"messages\"][-1].content\n",
    "# it is used to access the content of the last message \n",
    "# in a list stored under the key \"messages\" in a dictionary named value\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd7153",
   "metadata": {},
   "source": [
    "## 2. Let's enhance it where we will keep the conversation state using \"graph.invoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b95449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[AIMessage | HumanMessage], add_messages]\n",
    "    user_input: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = AgentState(messages=[], user_input=\"\")\n",
    "print(f\"Initial state: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51800a",
   "metadata": {},
   "source": [
    "### Now let's add functions to modify the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# 1. Function to take the user input and store it in AgentState\n",
    "def add_user_message(state: AgentState) -> AgentState:\n",
    "    new_query = HumanMessage(content=user_input)\n",
    "    return {\"messages\":[new_query], # Append new message\n",
    "           \"user_input\": \"\"}  # set back user input into None\n",
    "\n",
    "\n",
    "# 2. Function to call LLM and get response\n",
    "def generate_ai_response(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"messages\"])  # Call LLM API\n",
    "    return {\"messages\":[response], \"user_input\": \"\"}  # Append AI response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83b73e",
   "metadata": {},
   "source": [
    "### Let's create the graph instance to put together all the states and the functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea389cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initiate the graph instance from the main class StateGraph that hooks up the data stored in AgentState class\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# 2. Define nodes\n",
    "graph.add_node(\"add_user_message\", add_user_message)\n",
    "graph.add_node(\"generate_ai_response\", generate_ai_response)\n",
    "\n",
    "\n",
    "# 3. Define edges (flow of the graph)\n",
    "graph.add_edge(START, \"add_user_message\")\n",
    "graph.add_edge(\"add_user_message\", \"generate_ai_response\")\n",
    "graph.add_edge(\"generate_ai_response\", END)\n",
    "\n",
    "# 4. Convert the graph structure into an executable flow\n",
    "workflow = graph.compile() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a7e69",
   "metadata": {},
   "source": [
    "### Let's test and run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5eaace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize chatbot state and must the same class AgenState!\n",
    "state = AgentState(messages=[], user_input=\"\")\n",
    "print(f\"\\nInitial state: {state}\")\n",
    "\n",
    "\n",
    "# Simulate conversation\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "        \n",
    "    state[\"user_input\"] = user_input\n",
    "    state = workflow.invoke(state)  # Run the workflow and update state\n",
    "    bot_response = state[\"messages\"][-1].content  # Get last AI response\n",
    "    print(f\"Bot: {bot_response}\")\n",
    "    \n",
    "    print(f\"\\nUpdated state: {state}\") # Checkpoint to check the updated state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
