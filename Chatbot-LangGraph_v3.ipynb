{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e125434",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "ANTHROPIC_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1126e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Initialize OpenAI Chat Model\n",
    "llm_openai = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatAnthropic(model=\"claude-3-7-sonnet-20250219\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4ce5f",
   "metadata": {},
   "source": [
    "## 1. Constructing the basic langGraph flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[List[AIMessage | HumanMessage], add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0f355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chatbot(state: State) -> State:\n",
    "    bot_response = llm.invoke(state[\"messages\"])\n",
    "    print(state[\"messages\"]+[bot_response])\n",
    "    print(\"\\n\")\n",
    "    return {\"messages\": [bot_response]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f799c4",
   "metadata": {},
   "source": [
    "### Show the visual graph node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d4268",
   "metadata": {},
   "source": [
    "### Run the chatbot using \"graph.stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91121299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "# value[\"messages\"][-1].content\n",
    "# it is used to access the content of the last message \n",
    "# in a list stored under the key \"messages\" in a dictionary named value\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd7153",
   "metadata": {},
   "source": [
    "## 2. Let's enhance it where we will keep the conversation state using \"graph.invoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b95449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[AIMessage | HumanMessage], add_messages]\n",
    "    user_input: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = AgentState(messages=[], user_input=\"\")\n",
    "print(f\"Initial state: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51800a",
   "metadata": {},
   "source": [
    "### Now let's add functions to modify the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a932e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Qdrant (Local)\n",
    "qdrant_host = \"localhost\"\n",
    "qdrant_port = 6333\n",
    "collection_name = \"transformer_docs\"\n",
    "\n",
    "client = QdrantClient(host=qdrant_host, port=qdrant_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# 1. Function to take the user input and store it in AgentState\n",
    "def add_user_message(state: AgentState) -> AgentState:\n",
    "    new_query = HumanMessage(content=user_input)\n",
    "    return {\"messages\":[new_query]} # Append new message}\n",
    "\n",
    "# Helper function for retrieve relevant text\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list[float]:\n",
    "    response = openai.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# 2. Function to retrieve relevant text\n",
    "def retrieve_relevant_text(state: AgentState) -> AgentState:\n",
    "    \n",
    "    # Step 1: Get the latest user message\n",
    "    query = state['messages'][-1].content\n",
    "\n",
    "    # Step 2: Embed the query\n",
    "    query_vector = get_embedding(query)\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name= collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=3,  # Get top 3 similar results\n",
    "    )\n",
    "\n",
    "    extracted_data = [(res.payload[\"filename\"], res.payload[\"text\"]) for res in results]\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\" Please answer the query: {state['messages'][-1].content}\n",
    "    \n",
    "    based on the provided data {extracted_data}\n",
    "    \n",
    "    Please provide the response based on the provided data and your previous responses if the new query is the same, nothing else.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    rewritten_query = HumanMessage(content=prompt)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": rewritten_query\n",
    "    }\n",
    "\n",
    "def summarize_prompt(state: AgentState) -> AgentState:\n",
    "    answer = state['messages'][-1].content\n",
    "    print(f\"the answer from agent 1: {answer}\\n\")\n",
    "    \n",
    "    AI_prompt = f\"\"\"You are a data scientist and AI expert. Your responsibility is to respond to user's query on a mobile app, \n",
    "    hence your response should be short yet insightful.\n",
    "\n",
    "    The other data scientist has provided a long answer as follows:\n",
    "    {answer}\n",
    "    for this query: {state['user_input']}.\n",
    "\n",
    "    However if you see the answer is too long for users using mobile app and therefore this long answer might intimidate or confuse users, please provide a shorter yet insightful answer.\n",
    "    If you think it's useful to provide some details, please add on a URL link that the user can read it themselves. \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\" : AI_prompt\n",
    "    }\n",
    "\n",
    "    \n",
    "# 3. Function to call LLM and get response\n",
    "def generate_ai_response(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"messages\"])  # Call LLM API\n",
    "    return {\"messages\":[response]}  # Append AI response\n",
    "\n",
    "\n",
    "# 4. Function to call LLM and get response\n",
    "def short_ai_response(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"messages\"])  # Call LLM API\n",
    "    return {\"messages\":[response],  # Append AI response\n",
    "           \"user_input\": \"\"}  # Set back the user input to blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9959d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d83b73e",
   "metadata": {},
   "source": [
    "### Let's create the graph instance to put together all the states and the functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea389cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initiate the graph instance from the main class StateGraph that hooks up the data stored in AgentState class\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# 2. Define nodes\n",
    "graph.add_node(\"add_user_message\", add_user_message)\n",
    "graph.add_node(\"retrieve_relevant_text\", retrieve_relevant_text)\n",
    "graph.add_node(\"generate_ai_response\", generate_ai_response)  # Agent 1\n",
    "graph.add_node(\"summarize_prompt\", summarize_prompt)\n",
    "# graph.add_node(\"short_ai_response\", generate_ai_response)  # Agent 2\n",
    "graph.add_node(\"short_ai_response\", short_ai_response)  # Agent 2 : correction, it should be \"short_ai_response\"\n",
    "\n",
    "\n",
    "# 3. Define edges (flow of the graph)\n",
    "graph.add_edge(START, \"add_user_message\")\n",
    "graph.add_edge(\"add_user_message\", \"retrieve_relevant_text\")\n",
    "graph.add_edge(\"retrieve_relevant_text\", \"generate_ai_response\")\n",
    "graph.add_edge(\"generate_ai_response\", \"summarize_prompt\")\n",
    "graph.add_edge(\"summarize_prompt\", \"short_ai_response\")\n",
    "graph.add_edge(\"short_ai_response\", END)\n",
    "\n",
    "# 4. Convert the graph structure into an executable flow\n",
    "workflow = graph.compile() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(workflow.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a7e69",
   "metadata": {},
   "source": [
    "### Let's test and run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5eaace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize chatbot state and must the same class AgenState!\n",
    "state = AgentState(messages=[], user_input=\"\")\n",
    "print(f\"\\nInitial state: {state}\\n\")\n",
    "\n",
    "\n",
    "# Simulate conversation\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "        \n",
    "    state[\"user_input\"] = user_input\n",
    "    state = workflow.invoke(state)  # Run the workflow and update state\n",
    "    bot_response = state[\"messages\"][-1].content  # Get last AI response\n",
    "    print(f\"The answer from Agent 2: {bot_response}\")\n",
    "    \n",
    "#     print(f\"\\nUpdated state: {state}\") # Checkpoint to check the updated state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86eee56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ed362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8b78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4acd5f82",
   "metadata": {},
   "source": [
    "### 0. Offline part: Setting up vector database and the data processing for data extraction and vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09072a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Qdrant (Local)\n",
    "qdrant_host = \"localhost\"\n",
    "qdrant_port = 6333\n",
    "collection_name = \"transformer_docs\"\n",
    "\n",
    "client = QdrantClient(host=qdrant_host, port=qdrant_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbf3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(docs_list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=700,\n",
    "        chunk_overlap=50,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    return doc_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_doc = HuggingFaceDatasetLoader(\"m-ric/transformers_documentation_en\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8b224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer_splits = preprocess_dataset(transformers_doc.load()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0192c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in transformer_splits:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95529e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare OpenAI Embeddings\n",
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\") -> list[float]:\n",
    "    response = openai.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if collection_name not in [c.name for c in client.get_collections().collections]:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    "    )\n",
    "else:\n",
    "    print(\"Collection already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Batch\n",
    "import uuid\n",
    "\n",
    "ids = []\n",
    "vectors = []\n",
    "payloads = []\n",
    "\n",
    "# 1. Assign docs into list before uploading into Qdrant vector db\n",
    "for doc in transformer_splits:\n",
    "    text = doc.page_content\n",
    "    metadata = doc.metadata\n",
    "    \n",
    "    vector = get_embedding(text)\n",
    "    \n",
    "    ids.append(str(uuid.uuid4()))\n",
    "    vectors.append(vector)\n",
    "    payloads.append(metadata | {\"text\": text})\n",
    "\n",
    "    \n",
    "# 2. Upload vectors and payloads into Qdrant vector db\n",
    "client.upsert(\n",
    "    collection_name = collection_name,\n",
    "    points=Batch(\n",
    "        ids=ids,\n",
    "        vectors=vectors,\n",
    "        payloads=payloads   \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fec8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter\n",
    "from pprint import pprint\n",
    "\n",
    "# Scan through the stored documents and vector embedded\n",
    "scroll_result, next_page = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    limit=1,\n",
    "    with_payload=True,\n",
    "    with_vectors=True,\n",
    "    offset=None\n",
    ")\n",
    "\n",
    "for point in scroll_result:\n",
    "    print(f\"ID : {point.id}\")\n",
    "    pprint(point.payload)\n",
    "    pprint(point.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15e0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe39fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
